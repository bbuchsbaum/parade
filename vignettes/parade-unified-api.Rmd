---
title: "Unified API: Functions and Scripts, One Surface"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{0. Unified API: functions and scripts}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", eval = FALSE)
```

This vignette shows how the same Parade ergonomics apply whether you submit a
script or a function. You get one mental model and one set of verbs.

## Quick start: function first

```r
library(parade)
paths_init(quiet = TRUE)

# Submit a single function call
job <- slurm_call(
  function(x, y) x^2 + y^2,
  x = 3,
  y = 4,
  name_by = "index",
  engine = "local"
)
print(job)
cat("Result:", job$result, "\n")
```

## Map over inputs (function or script)

```r
files <- c("data1.csv", "data2.csv", "data3.csv")

# Function path
jobs <- slurm_map(files, ~ paste("Processing", .x), .name_by = "stem", .engine = "local")
results <- collect(jobs)

# Script path (CLI flags via args_cli)
jobs <- slurm_map(files, "scripts/process_one.R",
                  .args = args_cli(input = .x),
                  .name_by = stem())
```

## Elegant naming and paths

```r
# Naming helpers: stem/index/digest/glue_name
jobs <- slurm_map(files, ~ tools::file_path_sans_ext(.x),
                  .name_by = stem("sample_(\\d+)"), .engine = "local")

# Path macros in write_result
tmp <- tempdir()
jobs <- slurm_map(1:3, ~ .x^3,
                  .name_by = index("cube"),
                  .write_result = file.path(tmp, "results_{name}_{index}.rds"),
                  .engine = "local")
```

## Jobset verbs everywhere

All jobset verbs (`await`, `status`, `collect`, `cancel`, `progress`, `open_logs`) work on
results from `slurm_map()`. If you submit a single function with `slurm_call()`, add
`.as_jobset = TRUE` to opt into the same surface:

```r
# Wrap a single job as a one‑element jobset
jobs <- slurm_call(
  function(file) { Sys.sleep(1); read.csv(file)[1:5, ] },
  file = "data/example.csv",
  name = "proc-example",
  write_result = path$artifacts("results/{run}/{stem}.rds"),
  .as_jobset = TRUE
)

# Same verbs as slurm_map()
jobs |> progress() |> collect()
open_logs(jobs, selection = "all")
```

## Parallel arguments with pmap

```r
df <- data.frame(x = 1:4, y = 5:8, method = c("add","multiply","add","multiply"))
jobs <- slurm_pmap(df, function(x, y, method) if (method == "add") x + y else x * y,
                   .name_by = glue_name("{method}-{x}-{y}"), .engine = "local")
collect(jobs)
```

## Argument helpers

```r
# CLI arguments (scripts)
args_cli(input = "data.csv", output = "results.rds", verbose = TRUE, threads = 4)

# Function arguments
args_call(data = mtcars, formula = mpg ~ cyl + wt, method = "lm")
```

## Summary

- “One surface”: scripts via `submit_slurm()`, functions via `slurm_call()`
- `slurm_map()`/`slurm_pmap()` dispatch correctly for both kinds
- `name_by`, path macros, resource profiles, and flow control work uniformly
- Use `.as_jobset = TRUE` to get the same jobset verbs for single calls

