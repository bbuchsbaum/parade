---
title: "Scratch-first paths & registries: project://, artifacts://, registry://"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parade paths: portable aliases & scratch-first organization}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

> Requires **parade â‰¥ 0.6.0** (paths system with URI-style aliases).

## Path Management Philosophy

**parade** uses a **scratch-first** approach to path management that keeps your code portable between development and production environments. Instead of hardcoding file paths, parade uses **URI-style aliases** like `artifacts://models/` and `registry://templates/` that automatically resolve to appropriate locations on any system.

This design principle solves common HPC workflows where:

- **Development** happens on your laptop with small datasets
- **Production** runs on clusters with different filesystem layouts
- **Large outputs** need to go to fast scratch storage, not home directories
- **Code portability** is essential for reproducible research

## The Alias System

parade provides seven standard path aliases that cover different types of data and outputs:

```r
library(parade)

paths_init()
paths_get()
```

| Alias | Purpose | Default Location | HPC Considerations |
|-------|---------|-----------------|-------------------|
| `project://` | Source code, scripts | Working directory | Usually your home/project directory |
| `data://` | Input datasets | `project://data` | Readonly data, often shared |
| `scratch://` | Temporary storage | System temp or `$SCRATCH` | Fast local storage, not backed up |
| `artifacts://` | Analysis outputs | `scratch://parade-artifacts` | Large results, models, figures |
| `registry://` | Job templates, metadata | `scratch://parade-registry` | Workflow management files |
| `config://` | Settings, profiles | `project://.parade` | Configuration and profiles |
| `cache://` | Downloaded data, temp files | Platform-specific cache | Reusable downloaded content |

## Environment Detection and Setup

parade automatically detects your computing environment and configures appropriate defaults:

```r
# On laptop: uses project directories and system temp
paths_init()

# On SLURM cluster: automatically detects $SLURM_TMPDIR, $SCRATCH
paths_init()

# On PBS cluster: detects $PBS_O_WORKDIR, $TMPDIR  
paths_init()

# Manual override for specific environments
paths_init(profile = "hpc")
```

## Customizing Paths for HPC

For production HPC workflows, redirect large outputs to scratch storage:

```r
library(parade)

paths_init()

# Send big outputs & registries to scratch
paths_set(
  scratch   = "/scratch/$USER",
  artifacts = "/scratch/$USER/parade-artifacts", 
  registry  = "/scratch/$USER/parade-registry"
)

# Verify your configuration
paths_get()
```

### Environment Variable Override

Set environment variables to establish system-wide defaults:

```bash
# In your .bashrc or job scripts
export PARADE_SCRATCH="/fast/scratch/$USER"
export PARADE_ARTIFACTS="/fast/scratch/$USER/outputs"
export PARADE_REGISTRY="/shared/registry"
export PARADE_DATA="/shared/datasets"
```

## Using Path Aliases in Practice

### In Sink Specifications

```r
# Artifacts go to fast scratch storage
sink <- sink_spec(
  fields = c("model", "metrics"),
  dir = "artifacts://fits",
  template = "{.stage}/{subject}-{session}.rds"
)

# Configuration files stay with project
config_sink <- sink_spec(
  fields = "config",
  dir = "config://runs", 
  template = "run-{.row_key}.yaml"
)
```

### In File Operations

```r
# Load reference data
ref_data <- readRDS("data://reference/brain_atlas.rds")

# Save large model to artifacts
saveRDS(big_model, "artifacts://models/v1/final_model.rds")

# Store job template in registry
template_path <- "registry://templates/custom-slurm.tmpl"
writeLines(slurm_template, resolve_path(template_path))
```

### In Batch Job Templates

```r
# Template files use aliases for portability
tmpl <- scaffold_batch_template("slurm",
                               out = "registry://templates/parade-slurm.tmpl",
                               overwrite = TRUE)

# Generated jobs automatically resolve paths
grid <- param_grid(subject = paste0("s", 1:10))
job_script <- distribute(flow(grid), template = tmpl)
```

## Path Resolution Functions

parade provides two main functions for working with paths:

### `path_here()` - Direct alias resolution

```r
# Build paths from components
model_dir <- path_here("artifacts", "models", "v2")
config_file <- path_here("config", "analysis.yaml")

# Creates directories by default
output_path <- path_here("artifacts", "results", create = TRUE)

# Skip directory creation
temp_path <- path_here("scratch", "temp", create = FALSE)
```

### `resolve_path()` - URI-style path resolution

```r
# Convert URI aliases to absolute paths
model_path <- resolve_path("artifacts://models/final.rds")
data_path <- resolve_path("data://processed/clean_data.csv")

# Works with regular paths too
abs_path <- resolve_path("/absolute/path/file.txt")
rel_path <- resolve_path("relative/path/file.txt")

# Control directory creation
resolve_path("artifacts://new/dir/file.rds", create = FALSE)
```

## Computing Environment Examples

### Local Development

```r
# Typical laptop setup
paths_init()
#> parade paths: project=/home/user/myproject; scratch=/tmp/RtmpXXX; 
#>               data=/home/user/myproject/data; artifacts=/tmp/RtmpXXX/parade-artifacts

# Small datasets in project, outputs to temp
saveRDS(small_model, "artifacts://dev/test_model.rds")
```

### SLURM Cluster

```r
# Automatic SLURM detection
paths_init()
#> parade paths: project=/home/user/project; scratch=/tmp/slurm.123456; 
#>               artifacts=/tmp/slurm.123456/parade-artifacts

# Or explicit configuration
paths_set(
  scratch = Sys.getenv("SLURM_TMPDIR", "/tmp"),
  artifacts = file.path(Sys.getenv("SLURM_TMPDIR", "/tmp"), "outputs")
)
```

### Shared HPC System

```r
# System-wide configuration for all users
paths_set(
  data = "/shared/datasets",
  artifacts = "/scratch/$USER/parade-outputs", 
  registry = "/shared/parade-registry"
)

# Individual jobs automatically inherit these paths
grid <- param_grid(dataset = c("train", "test", "validation"))
flow(grid) |>
  stage("process", 
        f = function(dataset) {
          # Reads from shared location
          data <- readRDS(paste0("data://", dataset, ".rds"))
          # Writes to user's scratch  
          saveRDS(results, "artifacts://processed/{dataset}.rds")
        })
```

## Best Practices for Path Organization

### 1. Separate by Data Lifecycle

```r
# Raw, immutable inputs
"data://raw/experiment_2024.csv"

# Processed, intermediate results  
"artifacts://processed/clean_data.rds"

# Final outputs and models
"artifacts://final/publication_model.rds"

# Configuration and metadata
"config://profiles/hpc_settings.yaml"
```

### 2. Use Hierarchical Structure

```r
# Organize by analysis stage
"artifacts://preprocessing/subject_data/"
"artifacts://modeling/fitted_models/"  
"artifacts://evaluation/performance_metrics/"
"artifacts://visualization/figures/"

# Or by experimental condition
"artifacts://condition_A/session_{1:10}/"
"artifacts://condition_B/session_{1:10}/"
```

### 3. Environment-Specific Configuration

```r
# Development profile  
if (interactive()) {
  paths_set(
    artifacts = "artifacts://dev",
    scratch = tempdir()
  )
}

# Production profile
if (Sys.getenv("SLURM_JOB_ID") != "") {
  paths_set(
    artifacts = "/scratch/$USER/prod-outputs",
    registry = "/shared/workflows"  
  )
}
```

### 4. Portable Code Patterns

```r
# Good: Uses aliases, works everywhere
load_reference <- function() {
  readRDS("data://reference/brain_atlas.rds")
}

# Bad: Hardcoded paths, breaks on different systems
load_reference <- function() {
  readRDS("/home/user/data/brain_atlas.rds") 
}
```

The key insight is that parade's path system **separates logical organization from physical storage**, making your analysis code portable across any computing environment while automatically optimizing for local storage characteristics.
